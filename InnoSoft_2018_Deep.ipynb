{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InnoSoft 2018 Deep.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jutrera/InnoSoft-2018/blob/master/InnoSoft_2018_Deep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "D5X0ccEkeVbW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# InnoSoft 2018 - Deep Learning\n",
        "En este ejercicio vamos a entrenar un modelo de Deep Learning. Keras dispone de modelos ya preentrenados. En este caso entrenaremos una red ResNet\n",
        "\n",
        "## Preparamos el entorno"
      ]
    },
    {
      "metadata": {
        "id": "xPVZVvGQdu6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K-7GVuCHdyUF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YT5IpQb9d0Ab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive \n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qj6-Sm6Qd1Yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Files in Drive:')\n",
        "!ls drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtbWOxnLd5zN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QY6d36lte21j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## API de Kaggle\n",
        "Para acceder a los dataset, vamos a valernos de la API de Kaggle, el cual nos va a permitir descargarnos un conjunto de datos ya existente.\n",
        "\n",
        "En primer lugar, instalamos la API"
      ]
    },
    {
      "metadata": {
        "id": "7t4YRW6rd6H0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLksNl4cd_Js",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0x9v7W2lRN0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Guardamos el archivo de configuración en **root**."
      ]
    },
    {
      "metadata": {
        "id": "w-SZhZBKnjWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir '/root/.kaggle'\n",
        "!ls /content/.kaggle\n",
        "!cp \"/content/.kaggle/kaggle.json\" \"/root/.kaggle/kaggle.json\"\n",
        "\n",
        "!ls /root/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1yVNbwEfQ0K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos a hacer un listado de los dataset propios"
      ]
    },
    {
      "metadata": {
        "id": "OHb3UVcRr5NT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!kaggle datasets list -m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJI586utfXKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Y nos descargamos el dataset elegido"
      ]
    },
    {
      "metadata": {
        "id": "LvjuXtFTeavE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download --unzip 'jutrera/stanford-car-dataset-by-classes-folder'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLfpnhT-lfK6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Veamos la estruvtura de directorios"
      ]
    },
    {
      "metadata": {
        "id": "l-6YDZ607jka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls \"./\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoHUh0HSljD0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Descomprimiremos las imágenes."
      ]
    },
    {
      "metadata": {
        "id": "s6q_E3fdqTup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zf=zipfile.ZipFile(\"./car_data.zip\", \"r\")\n",
        "for i in zf.namelist():\n",
        "    zf.extract(i, path=\"./\")\n",
        "    \n",
        "!ls './car_data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBDbCGZil73d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos a ver una de las imágenes."
      ]
    },
    {
      "metadata": {
        "id": "_deYK52-0Ck0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_base = './'\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(path_base + '/car_data/train/Volvo XC90 SUV 2007') ]\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(path_base + '/car_data/train/Volvo XC90 SUV 2007/' + onlyfiles[0])\n",
        "\n",
        "imgplot = plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x4iaCmKuzd_K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Training data\n",
        "\n",
        "Empezamos importando librerías."
      ]
    },
    {
      "metadata": {
        "id": "FPvoWs9Qzdip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import misc\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from IPython.display import SVG\n",
        "import cv2\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JfKN5aVzlrM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import resnet50\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from keras import regularizers\n",
        "from keras_metrics import precision, recall\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ek9F7dbtmn9U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inicializamos y definimos valores para el entrenamiento (numero de epochs, tamaño del batch, etc)."
      ]
    },
    {
      "metadata": {
        "id": "LmjrBN_4zmQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.set_learning_phase(1)\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UFUl4_N2zo2s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_width, img_height = 224, 224\n",
        "nb_train_samples = 8144\n",
        "nb_validation_samples = 8041\n",
        "epochs = 2\n",
        "batch_size = 32\n",
        "n_classes = 196"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgLCXSy0mySp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###ImageDataGenerator\n",
        "La clase ImageDataGenerator de Keras nos permitirá trabajar con grandes cantidades de imágenes de tamaño mayor. Este generator nos permitirá ir cargando en batches definidos las imágenes y así no provocar fallos de memoria por volúmenes de dataset excesivamente altos. Además, nos permite incluir modificaciones en las imágenes tales como Zoom, Pan, Rotaciones, etc, lo que permite aumentar el tamaño de los datasets de imágenes y *emular* los fallos de las fotos (que no sean *perfectas*)."
      ]
    },
    {
      "metadata": {
        "id": "KR1RkR2mztqq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_dir = path_base + '/car_data/train'\n",
        "validation_data_dir = path_base + '/car_data/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range = 5,\n",
        "    width_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2zEn6SmynlIp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Entrenando una red profunda\n",
        "Con esto, podemos definir el modelo. En este caso vamos a entrenar una [DenseNet](https://arxiv.org/abs/1512.03385). Esta red se basa en que las salidas o resultados de cada **bloque denso** pasa a ser parte de la entrada de todos los bloques posteriores.\n",
        "\n",
        "![Diagrama de arquitectura DenseNet. Se representa un bloque denso de 5 capas con una tasa de crecimiento k = 4. Cada capa toma como entrada todos los valores de características anteriores](http://jesusutrera.com/articles/img/densenet01.jpg)\n",
        "\n",
        "Diagrama de arquitectura DenseNet. Se representa un bloque denso de 5 capas con una tasa de crecimiento k = 4. Cada capa toma como entrada todos los valores de características anteriores\n",
        "\n",
        "![Red neuronal de tres bloques densos. Las capas entre dos bloques adyacentes hacer referencia a una capa de transición cambiando el tamaño del mapa de características mediante convolución y pooling](http://jesusutrera.com/articles/img/densenet02.jpeg)\n",
        "\n",
        "Red neuronal de tres bloques densos. Las capas entre dos bloques adyacentes hacer referencia a una capa de transición cambiando el tamaño del mapa de características mediante convolución y pooling."
      ]
    },
    {
      "metadata": {
        "id": "bKs534W9osPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El siguiente ejercicio consiste en:\n",
        "1.  definir la red densa 121:\n",
        "  *  Definir el **input_shape=(None, None, 3)**,\n",
        "  *  cargar los pesos entrenados de **Imagenet**, \n",
        "  *  no incluir una capa densa por defecto (lo haremos nosotros) y\n",
        "  * definir el pooling **Average**.\n",
        "2.  Añadir a la red densa una capa de 500 nodos con activación ReLu."
      ]
    },
    {
      "metadata": {
        "id": "kCQrv1y-XKbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import densenet\n",
        "\n",
        "def build_model():\n",
        "  #Code here 1\n",
        "  base_model = densenet....\n",
        "  #End Code\n",
        "  \n",
        "  #Si se desea dejar los pesos originales sin actualizar, poner False (esto haría que solo se entrene las redes regulares finales)\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  #Asociamos la salida de la DenseNet y añadimos una capa densa de 1000 nodos\n",
        "  x = base_model.output\n",
        "  x = Dense(1000)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  \n",
        "  #Code here 2 - Añadir la capa densa de 500 nodos con activación ReLu\n",
        "  \n",
        "  #End Code\n",
        "  \n",
        "  #Definimos la salida al número de clases\n",
        "  predictions = Dense(n_classes, activation='softmax')(x)\n",
        "  \n",
        "  #y generamos el modelo\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtHF1_QnrRqv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La métrica RMSE (raíz cuadrada de la media de los errores cuadráticos) tiene la característica de que los valores tienen las mismas unidades que los valores de entrenamiento. Vamos a definir nuestra propia métrica. "
      ]
    },
    {
      "metadata": {
        "id": "EPgB6-EtHE_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rmse(y_true, y_pred):\n",
        "\treturn K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXr_uIz7r7tp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Debido a que el entrenamiento de una red profunda es largo y costoso, vamos a obtener los pesos de un entrenamiento previo. Si no, no daría tiempo a realizar este taller ;).\n",
        "\n",
        "Una vez cargados, compilamos el modelo."
      ]
    },
    {
      "metadata": {
        "id": "5weKa64oB9Sp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "path_to_load = \"drive/InnoSoft 2018/car_saved_01.h5\"\n",
        "model.load_weights(path_to_load)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mse', rmse])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVMB-XYgsZf9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hacemos un resumen del modelo construido. Podemos ver que, aunque hemos creado una red muy profunda, solo tenemos algo más de 8 millones de parámetros a entrenar. Si usaramos una red profunda más antigua, estaríamos hablando de 20 millones aproximadamente :(."
      ]
    },
    {
      "metadata": {
        "id": "WLMCWZKFz2jU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3XbZ-9Q3s37-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definimos los callback siguientes:\n",
        "* **Early stopping**: Si el modelo después de varias vueltas no mejora la función de perdida, paramos el entrenamiento.\n",
        "* **Reduce LR on plateau**: Si después de un n´mero determinado de vueltas, la función de pérdida no mejora, probamos a reducir el valor de **learning rate**. esto suele hacer que el entrenamiento mejore en muchos casos."
      ]
    },
    {
      "metadata": {
        "id": "WF5LO8yQvHYz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaxEB4VgvZ8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4pRk-Xw0Bgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks_list = [early_stop, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zsp8djyvtY0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Por último, entrenamos y vemos los resultados iniciales en la gráfica"
      ]
    },
    {
      "metadata": {
        "id": "U0-BxqKM0EC1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size,\n",
        "    callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kck_JkeD0HQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(model_history.history['acc'],'r')\n",
        "plt.plot(model_history.history['val_acc'],'g')\n",
        "plt.xticks(np.arange(0, epochs, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        " \n",
        "plt.figure(1)\n",
        "plt.plot(model_history.history['loss'],'r')\n",
        "plt.plot(model_history.history['val_loss'],'g')\n",
        "plt.xticks(np.arange(0, epochs, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(model_history.history['mean_squared_error'],'r')\n",
        "plt.plot(model_history.history['val_mean_squared_error'],'g')\n",
        "plt.xticks(np.arange(0, epochs, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Training MSE vs Validation MSE\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.figure(3)\n",
        "plt.plot(model_history.history['rmse'],'r')\n",
        "plt.plot(model_history.history['val_rmse'],'g')\n",
        "plt.xticks(np.arange(0, epochs, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(\"Training RMSE vs Validation RMSE\")\n",
        "plt.legend(['train','validation'])\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c8tzTWNztjpx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Si deseamos guardar el modelo entrenado, hacemos lo siguiente:"
      ]
    },
    {
      "metadata": {
        "id": "-sbiD-bdNeH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('drive/InnoSoft 2018/car_nosize.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tzFhJWjgtoUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finalmente, evaluamos el modelo y obtenemos la matriz de confusión y el informe"
      ]
    },
    {
      "metadata": {
        "id": "L_46tgmmHf-J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(validation_generator, steps=(nb_validation_samples // batch_size)+1, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMLByutFGvFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict_generator(validation_generator, steps=(nb_validation_samples // batch_size) + 1, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n",
        "predicted = np.argmax(pred, axis=1)\n",
        "print(predicted)\n",
        "print(len(predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKbGJF9GHD81",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "my_test = to_categorical(validation_generator.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V2FhBsZL3XRn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generamos el array de nombres de clases"
      ]
    },
    {
      "metadata": {
        "id": "Yu82_Rmv3Vf4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "class_names = []\n",
        "with open(path_base + '/names.csv') as csvDataFile:\n",
        "    csvReader = csv.reader(csvDataFile, delimiter=';')\n",
        "    for row in csvReader:\n",
        "        class_names.append(row[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JiRawLCGIMM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(validation_generator.classes, np.argmax(pred, axis=1))\n",
        "plt.figure(figsize = (30,20))\n",
        "sn.set(font_scale=1.4) #for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "plt.show()\n",
        "print()\n",
        "print('Classification Report')\n",
        "print(classification_report(validation_generator.classes, predicted, target_names=class_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GizmCoICG9cI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "n_classes = 196\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(my_test[:, i], pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(my_test.ravel(), pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(1)\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(10), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EoTuXks2t38q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hecho esto, podemos ver los resultados predichos por el modelo en algunas de las imágenes de validación"
      ]
    },
    {
      "metadata": {
        "id": "1qI6PewndUWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_one(model):\n",
        "    image_batch, classes_batch = next(validation_generator)\n",
        "    predicted_batch = model.predict(image_batch)\n",
        "    for k in range(0,image_batch.shape[0]):\n",
        "      image = image_batch[k]\n",
        "      pred = predicted_batch[k]\n",
        "      the_pred = np.argmax(pred)\n",
        "      predicted = class_names[the_pred]\n",
        "      val_pred = max(pred)\n",
        "      the_class = np.argmax(classes_batch[k])\n",
        "      value = class_names[np.argmax(classes_batch[k])]\n",
        "      plt.figure(k)\n",
        "      eso = (the_pred == the_class)\n",
        "      plt.title(str(eso) + ' - class: ' + value + ' - ' + 'predicted: ' + predicted + '[' + str(val_pred) + ']')\n",
        "      plt.imshow(image)\n",
        "\n",
        "predict_one(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}