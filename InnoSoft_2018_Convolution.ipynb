{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InnoSoft 2018 - Convolution",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jutrera/InnoSoft-2018/blob/master/InnoSoft_2018_Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZrFfdhLRz4UN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# InnoSoft 2018 - Convolutional nets\n",
        "\n",
        "## Preparamos el entorno"
      ]
    },
    {
      "metadata": {
        "id": "Vdmn6fqwm_OT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60Z2guCx0DDI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAt1R6Kc0Jvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive \n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GqTS4j8K0MNR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Files in Drive:')\n",
        "!ls drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zrJusUw70Qny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Obtenemos las librerías"
      ]
    },
    {
      "metadata": {
        "id": "hwWMv6-10SlY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import misc\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from IPython.display import SVG\n",
        "import cv2\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from keras import layers\n",
        "from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.utils import layer_utils, np_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras import losses\n",
        "from keras import regularizers\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJAMHzG30Vth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-metrics\n",
        "import keras_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKR2EDhM0aHU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Preparamos el conjunto de datos"
      ]
    },
    {
      "metadata": {
        "id": "alqfaFm30dSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar100\n",
        "\n",
        "(x_train_original, y_train_original), (x_test_original, y_test_original) = cifar100.load_data(label_mode='fine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m52bJTJa0jWR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imgplot = plt.imshow(x_train_original[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXEq3D9Z0l8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train_original, 100)\n",
        "y_test = np_utils.to_categorical(y_test_original, 100)\n",
        "\n",
        "x_train = x_train_original/255\n",
        "x_test = x_test_original/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsHlzVS80udh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Inicializamos Keras"
      ]
    },
    {
      "metadata": {
        "id": "v7Gql20A0xgB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.set_learning_phase(1)\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VBvOB7JYIcHo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Definimos la red convolutiva\n",
        "\n",
        "La red parte del conjunto de imágenes de 32x32x3. Queremos hacer lo siguiente:\n",
        "\n",
        "\n",
        "\n",
        "1.   Convolución de 32 kernels en ventanas de 3x3, con padding inicial de 2x2.\n",
        "2.   Convolución de 64 kernels en ventanas de 3x3, sin padding ni stride\n",
        "3.   Max Pooling en ventanas de 2x2\n",
        "4.   Convolución de 128 kernels en ventanas de 3x3.\n",
        "5.   Convolución de 256 kernels en ventanas de 3x3.\n",
        "6.   Convolución de 512 kernels de 3x3 y stride 2\n",
        "7.   Max Pooling de 2x2\n",
        "8.   Convolución de 1024 kernels de 3x3 y stride 2\n",
        "9.   Max Pooling de 2x2\n",
        "10. Flatten (conversión en array de dimensión 1)\n",
        "\n",
        "Para la función de activación se usará **ReLu**\n",
        "\n",
        "**Pistas**:\n",
        "*   Ver [Documentación Keras: Conv2D](https://keras.io/layers/convolutional/) para Padding y Convolución\n",
        "*   Ver [Documentación Keras: Pooling](https://keras.io/layers/pooling/) para Pooling\n",
        "*   Ver [Documentación Keras: Flatten](https://keras.io/layers/core/) para Flatten\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bTPYJVl2Ie6D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_cnn():\n",
        "  model = Sequential()\n",
        "  #Code here\n",
        "  \n",
        "  #Code here\n",
        "  model.add(Dense(500, activation='relu'))\n",
        "  model.add(Dropout(0.5)) #Add Dropout to \n",
        "  model.add(Dense(100, activation='softmax'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lMo-HD80Iq8y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Entrenamos la red creada"
      ]
    },
    {
      "metadata": {
        "id": "pRn6d4aVIqIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ConvNN = create_cnn()\n",
        "ConvNN.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YHjDhb4I16U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ConvNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3b6ecQ6EI43E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
        "\n",
        "cnn_history = ConvNN.fit(x=x_train, y=y_train, batch_size=32, epochs=20, verbose=1, validation_data=(x_test, y_test), shuffle=True, callbacks=[reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxEyiMDiJCBi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Vemos los resultados"
      ]
    },
    {
      "metadata": {
        "id": "cTrfkVEyJBBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(0)\n",
        "plt.plot(cnn_history.history['acc'],'r')\n",
        "plt.plot(cnn_history.history['val_acc'],'g')\n",
        "plt.xticks(np.arange(0, 15, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        " \n",
        "plt.figure(1)\n",
        "plt.plot(cnn_history.history['loss'],'r')\n",
        "plt.plot(cnn_history.history['val_loss'],'g')\n",
        "plt.xticks(np.arange(0, 15, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(cnn_history.history['mean_squared_error'],'r')\n",
        "plt.plot(cnn_history.history['val_mean_squared_error'],'g')\n",
        "plt.xticks(np.arange(0, 15, 1.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        " \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DzvcrKXVl5QY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ConvNN.save('drive/InnoSoft 2018/ConvNN_Model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lWkiawJnJGpn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evaluation = ConvNN.evaluate(x=x_test, y=y_test, batch_size=32, verbose=1)\n",
        "print(evaluation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8aJvKfDJIvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "cnn_pred = ConvNN.predict(x_test, batch_size=32, verbose=1)\n",
        "cnn_predicted = np.argmax(cnn_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmS0rVUgJK_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(np.argmax(y_test, axis=1), cnn_predicted)\n",
        "plt.figure(figsize = (30,20))\n",
        "sn.set(font_scale=1.4) #for label size\n",
        "sn.heatmap(cm, annot=True, annot_kws={\"size\": 12}) # font size\n",
        "plt.show()\n",
        "print()\n",
        "print('Classification Report')\n",
        "print(classification_report(np.argmax(y_test, axis=1), cnn_predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIMl3V0BJOHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "\n",
        "n_classes = 100\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], cnn_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), cnn_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(1)\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "for i, color in zip(range(10), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgY9jwIF_sBY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}